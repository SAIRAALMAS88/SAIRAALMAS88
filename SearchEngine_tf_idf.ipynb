{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMshVRoOCVzdzf6k27qhFgf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAIRAALMAS88/SAIRAALMAS88/blob/main/SearchEngine_tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Custom Search Engine Using Fine-Tuned LLMs\n"
      ],
      "metadata": {
        "id": "82gQXNBddnoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9Sg0rGQ0dmmb",
        "outputId": "1a5bc2d7-4521-4e13-bcfe-bdebeb281f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn nltk # Installing essential python packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPkvdcsJeeBH",
        "outputId": "cee2b215-1a82-4a9e-9862-2e0f18f3c36a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the corpus\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"Artificial intelligence is the future of technology.\",\n",
        "    \"The sun rises in the east and sets in the west.\",\n",
        "    \"Practice makes perfect.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power.\"\n",
        "]"
      ],
      "metadata": {
        "id": "zFpdR20Fet6q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre processing the Text\n",
        "def preprocess(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Preprocess the documents\n",
        "processed_docs = [preprocess(doc) for doc in documents]"
      ],
      "metadata": {
        "id": "f3gvqMmJe5Me"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute TF_IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(processed_docs)"
      ],
      "metadata": {
        "id": "uXYPPnfJe5QO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Search function\n",
        "def search(query, top_k=3):\n",
        "    # Preprocess the query\n",
        "    processed_query = preprocess(query)\n",
        "    # Convert query to TF-IDF vector\n",
        "    query_vector = vectorizer.transform([processed_query])\n",
        "    # Compute cosine similarity between query and documents\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "    # Sort documents by similarity score\n",
        "    sorted_indices = np.argsort(similarities)[::-1]\n",
        "    # Return top-k results\n",
        "    results = [(documents[i], similarities[i]) for i in sorted_indices[:top_k]]\n",
        "    return results"
      ],
      "metadata": {
        "id": "KVGFUri4e5Yn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Search Engine\n",
        "query = \"What is the future of technology?\"\n",
        "results = search(query, top_k=3)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"\\nTop Results:\")\n",
        "for i, (doc, score) in enumerate(results):\n",
        "    print(f\"{i+1}. Document: {doc}\\n   Similarity Score: {score:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z51TMGKpfZef",
        "outputId": "8e179ac4-8807-42b6-eca0-7ccb0a9c1baf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the future of technology?\n",
            "\n",
            "Top Results:\n",
            "1. Document: Artificial intelligence is the future of technology.\n",
            "   Similarity Score: 0.7071\n",
            "\n",
            "2. Document: Knowledge is power.\n",
            "   Similarity Score: 0.0000\n",
            "\n",
            "3. Document: Actions speak louder than words.\n",
            "   Similarity Score: 0.0000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}